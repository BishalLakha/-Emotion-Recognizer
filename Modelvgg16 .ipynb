{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The OS module in Python provides a way of using operating system dependent functionality. \n",
    "#import os\n",
    "# For array manipulation\n",
    "import numpy as np \n",
    "#For importing data from csv and other manipulation\n",
    "import pandas as pd\n",
    "\n",
    "#For displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "#For displaying graph\n",
    "#import seaborn as sns\n",
    "\n",
    "#For constructing and handling neural network\n",
    "import tensorflow as tf\n",
    "\n",
    "#Constants\n",
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_ITERATIONS = 10000 #increase iteration to improve accuracy           \n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 50\n",
    "IMAGE_TO_DISPLAY = 3\n",
    "VALIDATION_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from csv file\n",
    "data = pd.read_csv('Train_updated_six_emotion.csv')\n",
    "\n",
    "#Seperating images data from labels ie emotion\n",
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "#Normalizaton : convert from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "image_size = images.shape[1]\n",
    "image_width = image_height = 48\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJESBL0RCFPhCJESBL0RC/gf03BfTczP8MwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2acd84ac7090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying an image from 20K images\n",
    "def display(img):\n",
    "    #Reshaping,(1*2304) pixels into (48*48)\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    plt.axis('off')\n",
    "    #Show image\n",
    "    plt.imshow(one_image, cmap=cm.binary)     \n",
    "display(images[IMAGE_TO_DISPLAY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels[3] => [0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Creating an array of emotion labels using dataframe 'data'\n",
    "labels_flat = data[['label']].values.ravel()\n",
    "\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "# convert class labels from scalars to one-hot vectors\n",
    "# 0 => [1 0 0]\n",
    "# 1 => [0 1 0]\n",
    "# 2 => [0 0 1]\n",
    "def dense_to_one_hot(labels_dense, num_classes = 7):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "#Printing example  hot-dense label\n",
    "print ('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data for training & cross validation\n",
    "validation_images = images[:2000]\n",
    "validation_labels = labels[:2000]\n",
    "\n",
    "train_images = images[2000:]\n",
    "train_labels = labels[2000:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next is the neural network structure.\n",
    "#Weights and biases are created.\n",
    "#The weights should be initialised with a small a amount of noise\n",
    "#for symmetry breaking, and to prevent 0 gradients. Since we are using\n",
    "#rectified neurones (ones that contain rectifier function *f(x)=max(0,x)*),\n",
    "#we initialise them with a slightly positive initial bias to avoid \"dead neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weight\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "# We use zero padded convolution neural network with a stride of 1 and the size of the output is same as that of input.\n",
    "# The convolution layer finds the features in the data the number of filter denoting the number of features to be detected.\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Pooling downsamples the data. 2x2 max-pooling splits the image into square 2-pixel blocks and only keeps the maximum value \n",
    "# for each of the blocks. \n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images\n",
    "x = tf.placeholder('float', shape=[None, image_size])\n",
    "\n",
    "# labels (0, 1 or 2)\n",
    "y_ = tf.placeholder('float', shape=[None, labels_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 48, 48, 1)\n",
      "Tensor(\"Relu:0\", shape=(?, 48, 48, 8), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 48, 48, 8), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 24, 24, 16), dtype=float32)\n",
      "Tensor(\"Relu_3:0\", shape=(?, 24, 24, 16), dtype=float32)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "Tensor(\"Relu_5:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "Tensor(\"Relu_6:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "Tensor(\"Relu_7:0\", shape=(?, 6, 6, 32), dtype=float32)\n",
      "Tensor(\"Relu_8:0\", shape=(?, 6, 6, 32), dtype=float32)\n",
      "Tensor(\"Relu_9:0\", shape=(?, 6, 6, 32), dtype=float32)\n",
      "(?, 3, 3, 32)\n",
      "Tensor(\"Relu_10:0\", shape=(?, 3, 3, 32), dtype=float32)\n",
      "Tensor(\"Relu_11:0\", shape=(?, 3, 3, 32), dtype=float32)\n",
      "Tensor(\"Relu_12:0\", shape=(?, 3, 3, 32), dtype=float32)\n",
      "(?, 512)\n",
      "(?, 512)\n",
      "(?, 512)\n"
     ]
    }
   ],
   "source": [
    "W_conv1 = weight_variable([3, 3, 1, 8])\n",
    "b_conv1 = bias_variable([8])\n",
    "\n",
    "\n",
    "# we reshape the input data to a 4d tensor, with the first dimension corresponding to the number of images,\n",
    "# second and third - to image width and height, and the final dimension - to the number of colour channels.\n",
    "# (20000,2304) => (20000,48,48,1)\n",
    "image = tf.reshape(x, [-1,image_width , image_height,1])\n",
    "print (image.get_shape()) \n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1)\n",
    "print (h_conv1)\n",
    "\n",
    "\n",
    "\n",
    "W_conv2 = weight_variable([3, 3, 8, 8])\n",
    "b_conv2 = bias_variable([8])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "print (h_conv2)\n",
    "# pooling reduces the size of the output from 48x48 to 24x24.\n",
    "h_pool1 = max_pool_2x2(h_conv2)\n",
    "#print (h_pool1.get_shape()) => (20000, 24, 24, 8)\n",
    "\n",
    "# Prepare for visualization\n",
    "# display 8 features in 4 by 2 grid\n",
    "layer1 = tf.reshape(h_conv1, (-1, image_height, image_width, 4 ,2))  \n",
    "\n",
    "# reorder so the channels are in the first dimension, x and y follow.\n",
    "layer1 = tf.transpose(layer1, (0, 3, 1, 4,2))\n",
    "layer1 = tf.reshape(layer1, (-1, image_height*4, image_width*2))\n",
    "\n",
    "\n",
    "\n",
    "# The second layer has 16 features for each 5x5 patch. Its weight tensor has a shape of [5, 5, 8, 16].\n",
    "# The first two dimensions are the patch size. the next is the number of input channels (8 channels correspond to 8\n",
    "# features that we got from previous convolutional layer).\n",
    "\n",
    "W_conv3 = weight_variable([3, 3, 8, 16])\n",
    "b_conv3 = bias_variable([16])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3) + b_conv3)\n",
    "print(h_conv3)\n",
    "\n",
    "W_conv4 = weight_variable([3, 3, 16, 16])\n",
    "b_conv4 = bias_variable([16])\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4) + b_conv4)\n",
    "print(h_conv4)\n",
    "\n",
    "h_pool2 = max_pool_2x2(h_conv4)\n",
    "#print (h_pool2.get_shape()) => (20000, 12, 12, 16)\n",
    "\n",
    "# The third layer has 16 features for each 5x5 patch. Its weight tensor has a shape of [5, 5, 16, 32].\n",
    "# The first two dimensions are the patch size. the next is the number of input channels (16 channels correspond to 16\n",
    "# features that we got from previous convolutional layer)\n",
    "W_conv5 = weight_variable([3, 3, 16, 32])\n",
    "b_conv5 = bias_variable([32])\n",
    "h_conv5 = tf.nn.relu(conv2d(h_pool2, W_conv5) + b_conv5)\n",
    "print(h_conv5)\n",
    "\n",
    "\n",
    "W_conv6 = weight_variable([3, 3, 32, 32])\n",
    "b_conv6 = bias_variable([32])\n",
    "h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "print(h_conv6)\n",
    "\n",
    "W_conv7 = weight_variable([3, 3, 32, 32])\n",
    "b_conv7 = bias_variable([32])\n",
    "h_conv7 = tf.nn.relu(conv2d(h_conv6, W_conv7) + b_conv7)\n",
    "print(h_conv7)\n",
    "\n",
    "h_pool3 = max_pool_2x2(h_conv7)\n",
    "#print (h_pool2.get_shape()) => (20000, 6, 6, 32)\n",
    "\n",
    "\n",
    "W_conv8 = weight_variable([3, 3, 32, 32])\n",
    "b_conv8 = bias_variable([32])\n",
    "h_conv8 = tf.nn.relu(conv2d(h_pool3, W_conv8) + b_conv8)\n",
    "print(h_conv8)\n",
    "\n",
    "\n",
    "W_conv9 = weight_variable([3, 3, 32, 32])\n",
    "b_conv9 = bias_variable([32])\n",
    "h_conv9 = tf.nn.relu(conv2d(h_conv8, W_conv9) + b_conv9)\n",
    "print(h_conv9)\n",
    "\n",
    "W_conv10 = weight_variable([3, 3, 32, 32])\n",
    "b_conv10 = bias_variable([32])\n",
    "h_conv10 = tf.nn.relu(conv2d(h_conv9, W_conv10) + b_conv10)\n",
    "print(h_conv10)\n",
    "\n",
    "\n",
    "h_pool4 = max_pool_2x2(h_conv10)\n",
    "print (h_pool4.get_shape())\n",
    "# Now that the image size is reduced to 3x3, we add a Fully_Connected_layer) with 1024 neurones\n",
    "# to allow processing on the entire image (each of the neurons of the fully connected layer is \n",
    "# connected to all the activations/outpus of the previous layer)\n",
    "\n",
    "W_conv11 = weight_variable([3, 3, 32, 32])\n",
    "b_conv11 = bias_variable([32])\n",
    "h_conv11 = tf.nn.relu(conv2d(h_pool4, W_conv11) + b_conv11)\n",
    "print(h_conv11)\n",
    "\n",
    "W_conv12 = weight_variable([3, 3, 32, 32])\n",
    "b_conv12 = bias_variable([32])\n",
    "h_conv12 = tf.nn.relu(conv2d(h_conv11, W_conv12) + b_conv12)\n",
    "print(h_conv12)\n",
    "\n",
    "W_conv13 = weight_variable([3, 3, 32, 32])\n",
    "b_conv13 = bias_variable([32])\n",
    "h_conv13 = tf.nn.relu(conv2d(h_conv12, W_conv13) + b_conv13)\n",
    "print(h_conv13)\n",
    "\n",
    "\n",
    "\n",
    "# densely connected layer\n",
    "W_fc1 = weight_variable([3 * 3 * 32, 512])\n",
    "b_fc1 = bias_variable([512])\n",
    "\n",
    "# (20000, 6, 6, 32) => (20000, 1152 )\n",
    "h_pool2_flat = tf.reshape(h_conv13, [-1, 3*3*32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "print (h_fc1.get_shape()) # => (20000, 1024)\n",
    "\n",
    "W_fc2 = weight_variable([512, 512])\n",
    "b_fc2 = bias_variable([512])\n",
    "\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "print (h_fc2.get_shape()) # => (20000, 1024)\n",
    "\n",
    "W_fc3 = weight_variable([512, 512])\n",
    "b_fc3 = bias_variable([512])\n",
    "\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "print (h_fc3.get_shape()) # => (20000, 1024)\n",
    "\n",
    "# To prevent overfitting, we  apply dropout before the readout layer.\n",
    "# Dropout removes some nodes from the network at each training stage. Each of the nodes is either kept in the\n",
    "# network with probability (keep_prob) or dropped with probability (1 - keep_prob).After the training stage \n",
    "# is over the nodes are returned to the NN with their original weights.\n",
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "# readout layer 1024*3\n",
    "W_fc4 = weight_variable([512, labels_count])\n",
    "b_fc4 = bias_variable([labels_count])\n",
    "\n",
    "# Finally, we add a softmax layer\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc4) + b_fc4)\n",
    "#print (y.get_shape()) # => (20000, 3)\n",
    "\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "predict = tf.argmax(y,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.18 / 0.20 for step 0\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.20 for step 1\n",
      "training_accuracy / validation_accuracy => 0.22 / 0.20 for step 2\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.20 for step 3\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.20 for step 4\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.20 for step 5\n",
      "training_accuracy / validation_accuracy => 0.26 / 0.20 for step 6\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.20 for step 7\n",
      "training_accuracy / validation_accuracy => 0.48 / 0.34 for step 8\n",
      "training_accuracy / validation_accuracy => 0.30 / 0.36 for step 9\n",
      "training_accuracy / validation_accuracy => 0.30 / 0.36 for step 10\n",
      "training_accuracy / validation_accuracy => 0.22 / 0.20 for step 20\n",
      "training_accuracy / validation_accuracy => 0.24 / 0.20 for step 30\n",
      "training_accuracy / validation_accuracy => 0.22 / 0.20 for step 40\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.20 for step 50\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.20 for step 60\n",
      "training_accuracy / validation_accuracy => 0.14 / 0.20 for step 70\n",
      "training_accuracy / validation_accuracy => 0.24 / 0.20 for step 80\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.20 for step 90\n",
      "training_accuracy / validation_accuracy => 0.28 / 0.20 for step 100\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.20 for step 200\n",
      "training_accuracy / validation_accuracy => 0.32 / 0.20 for step 300\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.18 for step 400\n",
      "training_accuracy / validation_accuracy => 0.32 / 0.18 for step 500\n",
      "training_accuracy / validation_accuracy => 0.32 / 0.26 for step 600\n",
      "training_accuracy / validation_accuracy => 0.12 / 0.30 for step 700\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.22 for step 800\n",
      "training_accuracy / validation_accuracy => 0.32 / 0.28 for step 900\n",
      "training_accuracy / validation_accuracy => 0.44 / 0.26 for step 1000\n",
      "training_accuracy / validation_accuracy => 0.38 / 0.34 for step 2000\n",
      "training_accuracy / validation_accuracy => 0.34 / 0.34 for step 3000\n",
      "training_accuracy / validation_accuracy => 0.40 / 0.34 for step 4000\n",
      "training_accuracy / validation_accuracy => 0.44 / 0.34 for step 4999\n",
      "validation_accuracy => 0.3475\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2acd4f556190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # visualisation variables\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "    x_range = []\n",
    "\n",
    "    display_step=1\n",
    "\n",
    "    for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "        #get new batch\n",
    "        batch_xs, batch_ys = next_batch(BATCH_SIZE)        \n",
    "\n",
    "        # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "        if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch_xs, \n",
    "                                                      y_: batch_ys, \n",
    "                                                      keep_prob: 1.0})       \n",
    "            if(VALIDATION_SIZE):\n",
    "                validation_accuracy = accuracy.eval(feed_dict={ x: validation_images[0:BATCH_SIZE], \n",
    "                                                                y_: validation_labels[0:BATCH_SIZE], \n",
    "                                                                keep_prob: 1.0})                                  \n",
    "                print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "\n",
    "                validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "            else:\n",
    "                 print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            x_range.append(i)\n",
    "\n",
    "            # increase display_step\n",
    "            if i%(display_step*10) == 0 and i:\n",
    "                display_step *= 10\n",
    "        # train on batch\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: DROPOUT})\n",
    "        \n",
    "        \n",
    "        \n",
    "    if(VALIDATION_SIZE):\n",
    "        validation_accuracy = accuracy.eval(feed_dict={x: validation_images, \n",
    "                                                       y_: validation_labels, \n",
    "                                                       keep_prob: 1.0})\n",
    "        print('validation_accuracy => %.4f'%validation_accuracy)\n",
    "        plt.plot(x_range, train_accuracies,'-b', label='Training')\n",
    "        plt.plot(x_range, validation_accuracies,'-g', label='Validation')\n",
    "        plt.legend(loc='lower right', frameon=False)\n",
    "        plt.ylim(ymax = 1.1, ymin = 0.0)\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('step')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2 (Intel, 2018 update 1)",
   "language": "python",
   "name": "intel_distribution_of_python_2_2018u1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
